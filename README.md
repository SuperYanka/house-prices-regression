# Contents/–û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

* [EN](#en)
* [RU](#ru)


# *EN*

# üè° House Prices ‚Äî Advanced Regression Techniques

Predicting the sale price of a house based on various features using multiple regression models.

## Project Goal

Build regression models to predict `SalePrice` of houses using data from the [Kaggle: House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques) competition.

## Work stages

### 1. EDA (Data Analysis)
- Gaps and distribution features identified
- Target variable transformed: logarithmic transformation `log1p(SalePrice)`
- Distribution, dependency and correlation graphs constructed

### 2. Feature Engineering
- Feature `LogSalePrice` created
- Gaps filling: median (numeric), mode (categorical)
- Scaling of numeric features
- One-Hot Encoding of categorical

### 3. Model training
Models were used with pipelines:
- Linear Regression
- Ridge Regression
- Lasso Regression
- Random Forest Regressor

### 4. Metrics and comparison
Metrics (MAE, MSE, R¬≤) and ROC/Confusion Matrix comparison graphs for models are presented in the `plots` folder.

![Model Comparison](./plots/metrics_comparison.png)

### 5. Summary
Random Forest showed the best performance:
- MAE: 0.039
- MSE: 0.004
- R¬≤: 0.978

## Project structure

‚îú‚îÄ‚îÄ data/ # train.csv and test.csv data

‚îú‚îÄ‚îÄ src/

‚îÇ ‚îú‚îÄ‚îÄ preprocess.py # Data preprocessing

‚îÇ ‚îú‚îÄ‚îÄ train_lasso.py # Lasso training

‚îÇ ‚îú‚îÄ‚îÄ train_rf.py # RandomForest

‚îÇ ‚îî‚îÄ‚îÄ ...

‚îú‚îÄ‚îÄ models/ # Saved models and metrics

‚îú‚îÄ‚îÄ plots/ # Model comparison plots

‚îú‚îÄ‚îÄ notebooks/EDA.ipynb, plots.ipynb

‚îú‚îÄ‚îÄ submissions/ # CSV files for Kaggle

‚îú‚îÄ‚îÄ README.md # This file

## Skills and technologies

- Pandas, NumPy, Matplotlib, Seaborn
- Scikit-learn (Pipeline, ColumnTransformer, models, metrics)
- Feature Engineering
- Working with Git/GitHub
- Machine learning principles (regression, log transforms)
- Model evaluation

## Links

- [Kaggle project](https://www.kaggle.com/code/yaninakostiv/eda-house-prices)
- [GitHub repository](https://github.com/SuperYanka/house-prices-regression)
- [Profile in LinkedIn](https://www.linkedin.com/in/superyanka/)

---

# *RU*

# üè° House Prices ‚Äî Advanced Regression Techniques

–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã –ø—Ä–æ–¥–∞–∂–∏ –¥–æ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.

## –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è `SalePrice` –¥–æ–º–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ —Å —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è [Kaggle: House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques).

## –≠—Ç–∞–ø—ã —Ä–∞–±–æ—Ç—ã

### 1. EDA (–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö)
- –í—ã—è–≤–ª–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
- –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ `log1p(SalePrice)`
- –ü–æ—Å—Ç—Ä–æ–µ–Ω—ã –≥—Ä–∞—Ñ–∏–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π

### 2. Feature Engineering
- –°–æ–∑–¥–∞–Ω –ø—Ä–∏–∑–Ω–∞–∫ `LogSalePrice`
- –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤: –º–µ–¥–∏–∞–Ω–∞ (—á–∏—Å–ª–æ–≤—ã–µ), –º–æ–¥–∞ (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ)
- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- One-Hot Encoding –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö

### 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
–ú–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å —Å –ø–∞–π–ø–ª–∞–π–Ω–∞–º–∏:
- Linear Regression
- Ridge Regression
- Lasso Regression
- Random Forest Regressor

### 4. –ú–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
–ú–µ—Ç—Ä–∏–∫–∏ (MAE, MSE, R¬≤) –∏ –≥—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ROC/Confusion Matrix –¥–ª—è –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –ø–∞–ø–∫–µ `plots`.

![Model Comparison](./plots/metrics_comparison.png)

### 5. –ò—Ç–æ–≥
–õ—É—á—à—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–∫–∞–∑–∞–ª Random Forest:
- MAE: 0.039
- MSE: 0.004
- R¬≤: 0.978

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

‚îú‚îÄ‚îÄ data/ # –î–∞–Ω–Ω—ã–µ train.csv –∏ test.csv

‚îú‚îÄ‚îÄ src/

‚îÇ ‚îú‚îÄ‚îÄ preprocess.py # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

‚îÇ ‚îú‚îÄ‚îÄ train_lasso.py # –û–±—É—á–µ–Ω–∏–µ Lasso

‚îÇ ‚îú‚îÄ‚îÄ train_rf.py # RandomForest

‚îÇ ‚îî‚îÄ‚îÄ ...

‚îú‚îÄ‚îÄ models/ # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç—Ä–∏–∫–∏

‚îú‚îÄ‚îÄ plots/ # –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π

‚îú‚îÄ‚îÄ notebooks/EDA.ipynb, plots.ipynb

‚îú‚îÄ‚îÄ submissions/ # CSV-—Ñ–∞–π–ª—ã –¥–ª—è Kaggle

‚îú‚îÄ‚îÄ README.md # –≠—Ç–æ—Ç —Ñ–∞–π–ª


## –ù–∞–≤—ã–∫–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- Pandas, NumPy, Matplotlib, Seaborn
- Scikit-learn (Pipeline, ColumnTransformer, –º–æ–¥–µ–ª–∏, –º–µ—Ç—Ä–∏–∫–∏)
- Feature Engineering
- –†–∞–±–æ—Ç–∞ —Å Git/GitHub
- –ü—Ä–∏–Ω—Ü–∏–ø—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (—Ä–µ–≥—Ä–µ—Å—Å–∏—è, –ª–æ–≥-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è)
- –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π

## –°—Å—ã–ª–∫–∏

- [–ü—Ä–æ–µ–∫—Ç –Ω–∞ Kaggle](https://www.kaggle.com/code/yaninakostiv/eda-house-prices)
- [–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–∞ GitHub](https://github.com/SuperYanka/house-prices-regression)
- [–ü—Ä–æ—Ñ–∏–ª—å –≤ LinkedIn](https://www.linkedin.com/in/superyanka/)

---

